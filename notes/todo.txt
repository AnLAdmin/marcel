- Complete Python string parsing

- Complete shell string parsing (termination on things other than EOL
  and whiteapce).

- Debugging & verbosity level

- What happens to processes that disappear? E.g. ps | .... ps yields
  non-existent processes which are then used downstream. Can this even
  happen?

- ps: If commandline blank, take contents of Name from status file
  (enclosed in [])? That's what ps appears to do.

----------------------------------------------------------------------

- Organize internal ops -- Fork, LabelThread

- How do exit codes fit in?

----------------------------------------------------------------------

Provide a way to specify farcel config path. Maybe as a property of
the cluster.

----------------------------------------------------------------------

Distinct color for broken symlink.

----------------------------------------------------------------------

Tab completion:

- Tab completion for command should distinguish between first op of
  pipeline and subsequent ones. I.e., only show those ops that can be
  used in the current position within the pipeline.

- Tab completion for directory should include / at end.

- Tab completion for file should include ' ' at end.

- Tab completion with more alternatives should end on the last common
  character.

----------------------------------------------------------------------

Add notion of current job, and then allow bg/fg ops to omit args.

----------------------------------------------------------------------

Would multiprocessing.Process provide better streaming than
subprocess.Popen? I.e., not waiting for op to complete.

----------------------------------------------------------------------

Make Bash.INTERACTIVE_EXECUTABLES an environment variable, so that it
can be customized by the user.

----------------------------------------------------------------------

Import bash env?

----------------------------------------------------------------------

Red:

- Need a red function for creating a list. + isn't a good choice, since it
  already does expected things for numbers and strings. 

- Can squish be eliminated in favor of some variation of red? 

Could at least generalize similar to expand. E.g. squish 1 would take
a sequence in position 1 and squish just that. So

(1, [[1]])
(2, [[2], [2]])
(3, [[3], [3], [3]])

 ->

(1, [1])
(2, [2, 2])
(3, [3, 3, 3])

----------------------------------------------------------------------

Should help output go through more?

----------------------------------------------------------------------

Configuration:

- Look in ~, /etc/marcel.

- Be able to specify config file (or multiple locations) in startup.

----------------------------------------------------------------------

History commands

- If history were in the namespace, then edited_command wouldn't need
  special handling.

----------------------------------------------------------------------

timer: allow interval to be an int or real (#sec)

----------------------------------------------------------------------

Revert to pickling if dill not present. And in that case, require
function source for remote execution.

----------------------------------------------------------------------

Not all ops can be used in API, e.g. edit, help. What about fork? remote?

----------------------------------------------------------------------

API needs documentation. help? HTML?

----------------------------------------------------------------------

Exit codes? (Not just an api issue)

----------------------------------------------------------------------

window: what is supposed to happen if overlap = 0? disjoint = 0? Not tested.
test types other than int

----------------------------------------------------------------------

sudo has a zillion args. How to express this on sudo()? **kwargs?

----------------------------------------------------------------------

todo: fork doc describes remote execution. Doesn't discuss @int, or
@sequence. Does @sequence even work? Non-remote versions are kind of
useless without more interesting kinds of sequences, and a way for
each copy of the pipeline to access the label.

----------------------------------------------------------------------

Merge Env and Main? Or maybe make Main the thing that is available
globally?

----------------------------------------------------------------------

first constructs an Exception out of an Error.

Is it feasible to have Error carry the original exception, and reraise
it, or at least an exception of the same type? What if the Error was
remote?

----------------------------------------------------------------------

ls spacing is too wide. How to pick a width? Buffer results? Don't
buffer and adapt?

----------------------------------------------------------------------

This is broken: Op.op_name() evalutes to "op".

    @staticmethod
    def check_arg(ok, arg, message):
        if not ok:
            cause = (f'Incorrect usage of {Op.op_name()}: {message}'
                     if arg is None else
                     f'Incorrect value for {arg} argument of {Op.op_name()}: {message}')
            raise marcel.exception.KillCommandException(cause)

----------------------------------------------------------------------

Import selected bash env variables? Can't see anything other than
EDITOR right now.

----------------------------------------------------------------------

ps lines are often long enough to wrap. Should render_full leave off
args? If so, then provide an args method.

----------------------------------------------------------------------

What if there are two shells running at the same time -- how is
history file maintained? Probably lose updates from the first one to
exit. How should this be handled? To be safe, on exit, should read,
append, write. Atomically.

----------------------------------------------------------------------

Cluster.set_host called by Remote.setup_2 and
Fork.attach_thread_label. Unclear why both are needed.

----------------------------------------------------------------------

API has fork and remote, and they are bound bound to Fork. remote
*intended* for remote execution. 

Need both remote and fork ops?

----------------------------------------------------------------------

Should jobs and commands be objects? That would allow for better
formatting.

----------------------------------------------------------------------

Should {...} work as a glob pattern? It does in bash. pathlib.Path.glob
doesn't.

ls -fr ~/git/marcel/{marcel,test} \
| select (f: f.suffix == '.py') \
| map (f: f.readlines()) \
| expand \
| red count
No qualifying paths: ['~/git/marcel/{marcel,test}']

----------------------------------------------------------------------

cat = [ map (f: (f, f.readlines())) | expand 1 ]
(cat)

prints:

    pipeline(map(f: (f, f.readlines())) | expand(1))

It would be nice to have the original source.

----------------------------------------------------------------------

These commands do different things:

    ls -fr **/*.py
    ls -fr | select (f: f.suffix == '.py')

The first one avoids symlinks (or symlinks to visited directories? or
files?). The second one explores both paths.

----------------------------------------------------------------------

I keep forgetting to set pipeline's error handler. Could be done by
Pipeline.copy.

----------------------------------------------------------------------

env has paths as strings. Should be Paths.

----------------------------------------------------------------------

Make namespace protected. Use vars() instead externally.  BTW:
"vars()" is not a good name for returning the namespace. globals()?

----------------------------------------------------------------------

ls API: Need to complain if depth is other than 0 or 1

----------------------------------------------------------------------

Exhaustive type error testing in API?

----------------------------------------------------------------------

stack traces: Include them, but have print_stack check a flag to
determine if they should really be printed.

----------------------------------------------------------------------

TestBase.reset_environment does too much. Move everything but Main
construction into subclasses.

----------------------------------------------------------------------

Controlling Popen processes:

https://pymotw.com/2/subprocess/#process-groups-sessions

----------------------------------------------------------------------

Pipelines:

- In parser, the create_op_variable check is useless. The variable
  value could change before execution, and may even cease to
  exist. Make create_op_variable the last resort, and then at runtime,
  complain if the var isn't defined, or if it's value is of the wrong
  type.

- Allow [...] to delimit a pipeline, even when not necessary. (Like {
  ... } around single statement if, in C.)


Should assign allow assignment of pipeline without brackets?

----------------------------------------------------------------------

Should a var hide an op by the same name?

----------------------------------------------------------------------

Oops, [] is overloaded:

M-0.9.17 jao@cheese:/tmp/csv$ ls [b-f]*.csv
Operator ls: filenames must be a string: [runpipeline(b-f)]

But escaping works:

M-0.10.6 jao@cheese:~$ ls \[p-r\]*
-rw-rw-r--   jao    jao       36883   2020 Jul 05 19:23:14   passwords.txt
-rw-r--r--   jao    jao       13377   2019 Jan 20 12:43:37   reality_distortion_field.md
-rw-rw-r--   jao    jao        2415   2019 Oct 06 23:13:49   reload.txt


----------------------------------------------------------------------

Can't run ssh!

----------------------------------------------------------------------

env options to print one var, or to find a var. Autocomplete.

----------------------------------------------------------------------

Replace now() by time(). (Code, doc)

----------------------------------------------------------------------

EDITOR set to host's EDITOR on startup. Which is convenient, but odd
if host value changes. How to keep the two in sync? Maybe reporting
EDITOR should always get the value of os.getenv('EDITOR')?

----------------------------------------------------------------------

Nushell uses $it for current pipeline item. Not a bad
idea. Alternative to args (without --all).

----------------------------------------------------------------------

TYPE SAFETY

----------------------------------------------------------------------

out

- -t|--tsv
- -p|--pickle

read would need -p also.

About the names: read/out are inconsistent. Should be read/write, or in/out.
But in is a reserved word, so that creates problems for the API.

Maybe use read/write, and allow "out" as an alternative to write?

----------------------------------------------------------------------

Suppose that an op with a pipeline arg does a send from receive_complete, e.g. 

    join [... red +] | ...

Will the join be correct? The red + can do such a "late" send. The
fact that red's receive_complete was called means that the join has
reached receive_complete too.

----------------------------------------------------------------------

Tab completion:

- We often know when an op ends. Can tab-complete for |, >, >>, [, ], Enter.

- We sometimes know when an arg is not a flag. Can prompt for var, (, [.

----------------------------------------------------------------------

env is hard to read. Make it easier:

- Formatting of ColorScheme.

- make functions more presentable.

----------------------------------------------------------------------

Help needs to discuss >, >>, pipeline params.

help pipeline, examples summing filesizes are inconsistent. Unclear
that early ones compute local sum of sizes, and later ones are global.

----------------------------------------------------------------------

In api functions, why [None] instead of []? E.g., in store()

----------------------------------------------------------------------

File.unlink()

----------------------------------------------------------------------

ls gets COLOR_SCHEME on each File:

M-0.11.0 jao@cheese:~/git/marcel/marcel$ ls | ext py 
getvar 139884242926800: PWD -> 139884242937296
getvar 139884242926800: ext -> 139884241896976
runpipeline.setup_1 ext: 139884241896976 [e: select(lambda f: f.suffix == '.' + e)]
runpipeline.setup_1 pipeline env: <marcel.env.Environment object at 0x7f39569bfcd0>
getvar 139884242926800: COLOR_SCHEME -> 139884242927472
-rw-r--r--   jao    jao         652   2020 May 10 15:41:11   __init__.py
getvar 139884242926800: COLOR_SCHEME -> 139884242927472
-rw-rw-r--   jao    jao        7591   2020 Oct 08 14:28:17   api.py
getvar 139884242926800: COLOR_SCHEME -> 139884242927472
-rw-rw-r--   jao    jao       18875   2020 Oct 05 12:02:02   argsparser.py
getvar 139884242926800: COLOR_SCHEME -> 139884242927472
-rw-rw-r--   jao    jao        1356   2020 Oct 09 11:24:21   builtin.py
getvar 139884242926800: COLOR_SCHEME -> 139884242927472
-rw-rw-r--   jao    jao       12925   2020 Oct 11 13:22:27   core.py
getvar 139884242926800: COLOR_SCHEME -> 139884242927472
-rw-rw-r--   jao    jao       11985   2020 Oct 11 13:26:13   env.py
getvar 139884242926800: COLOR_SCHEME -> 139884242927472
-rw-r--r--   jao    jao        4506   2020 Aug 21 09:20:16   exception.py
getvar 139884242926800: COLOR_SCHEME -> 139884242927472

----------------------------------------------------------------------

For remote execution, is it still necessary to transmit env
separately? Just send the pipeline as is, don't detach/retach env
(which is vestigial anyway).

----------------------------------------------------------------------

Instead of serializing Pipelines, how about serializing pipeline
strings, and them parse them on the other side? This is doable except
for API pipelines containing native functions.

----------------------------------------------------------------------

Replace /proc usage by OS calls?

See psutil

----------------------------------------------------------------------

history:

Add flags:

    -n: n is int, list last n

    -c x: list items containg x

----------------------------------------------------------------------

Start this command: ls -r ~ > ./x, and put it in the background.

Monitoring progress is problematic.

- Checking the file size works.

- Running tail occasionally: It executes but
  shouldn't. PickleFile.reader() asserts that there are no writers,
  and that's not firing.

- Ignoring that, tail usually fails: _pickle.UnpicklingError: pickle
  data was truncated. I'm guessing that dill.dump() flushes to disk on
  buffer boundaries, not object boundaries, so reading a file while
  it's being written can't work.

BUT: 

- pickle seems to avoid this problem. Or at least it's much rarer.

- pickle is also a lot faster, 20x. See experiments/dill_vs_pickle.py

----------------------------------------------------------------------

Honestly, the marcel equivalent to grep is kind of a pain.

    grep foo *.txt

->

    read -l *.txt | select (file, line: 'foo' in line) | map (file, line: file)

Can grep (at least, this simplified usage) be expressed as a pipeline?

grep = [pattern, files: read -l (files) | select (f, l: pattern in l) | map (f, l: f) | unique]

Yes! except that "grep" is understood to be an executable. Need to
work out order of resolution (e.g., want vars before executables).

----------------------------------------------------------------------

Operator and pipeline logging, easily controllable, is needed. Can
this be done avoiding runtime penalty when logging not in use?

----------------------------------------------------------------------

Error handling needs to be revisited.
