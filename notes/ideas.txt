Name: marcel. As in Marcel the Shell.

----------------------------------------------------------------------

Structured Output:

ls -l doesn't make sense for osh. Allow for formatting options:

- Varying levels of detail. E.g. ls | out -l0 would produce just
  filenames. ls | out -l1 would do be the equivalent of ls -l, and ls
  | out -l2 would be even more detail.

- This applies to other objects too, e.g. Process.

----------------------------------------------------------------------

Functions and ops

- There is already a ps command and a processes() function.

- There is a cd command. There is no cd function, which would be
  useful, e.g. to simulate du -hs:

  ls -d | cd(...) | ls -fr(...) | map (f: (1, f.size)) | red + +

For each directory in current directory: cd to it, then recursively
find files, counting and summing sizes.

Needs ls and cd working as functions.




ls -d | map (dir: ls(-fr, dir)) | expand | map (f: (1, f.size)) | red + +


ls -d | (dir: (dir, ls('-fr', dir)) | expand 1 | (f: (dir, 1, f.size)) | red . + +

- An explicit "map" is noisy and can be inferred.

- But inside the function, we're supposed to have pure python. How are
  flags specified? (ls -fr)

- Environment variables: 

    ls -d | (dir: ls -fr $dir) | ...

  yechh. It means we have two kinds of variables, two kinds of
  function. And the function syntax is now no longer always python.

  But that's the case anyway, if we use "ls -fr | ..." on the command
  line and "ls('-fr') | ..." in Python.

  Hmm.

What about Python syntax everywhere?

  (ls('-d')) | (dir: (dir, ls('-fr', dir))) | expand 1 | (dir, f: (dir, 1, f.size)) | red . + +


Maybe shell syntax is defined to be syntactic sugar for function invocation. So 

      ls -fr d/*

is equivalent to

      (ls('-fr d/*'))

And either is acceptable as input? The function then has to yield a
stream, not a sequence.

Could have a "stream" operator, e.g. stream (ls()), but that's
basically "ls() | expand". And stream is less general.

----------------------------------------------------------------------

send/receive vs. yield

Could write operators as python generators, providing output via
yield. For operators other than the first, an input source is
needed. E.g., here is map.receive:

    def receive(self, x):
        self.send(self.f(*x))

Instead, it would be

    def run(self):
        try:
            input = self.input.run()
            while True:
                yield self.f(next(input))
        except StopIteration:
            ...

So instead of calling self.send (implying something downstream), you
know about the thing upstream (self.input). And yield is native
python, not an osh API.

So for the first item in a pipeline, it would just be "yield", and
there is no dependence on other operators. This allows ps(), ls(),
etc. to be used as functions or operators.
        
----------------------------------------------------------------------

Realization!

processes() is a function returning a list of Process. ps() is a
command generating a stream of Process. They can't be unified without
making processes() generate a stream, perhaps using yield. But in
other situations, we really want ordinary functions, e.g. for use in
map and select.

So:

ls:

- The kinds of functions used in map and select are ordinary python
  functions. Leave those alone, they are fine as is.

- If we want to unify ps()/ps, or ls()/ls, then we need python
  generators. 

Here is the implementation of ls()

- It creates an instance of class Ls.

- Ls extends Op.

- Ls has fields corresponding to the flags of the ls operator, and a
  few others.

- Ls has a __doc__ string, returned by doc().

- Initialization is done by setup() (after flag parsing)

- Ls has a parser, and returns it using arg_parser()

- execute() does the work, eventually calling send()

ps:

Similar to the above, but execute simply invokes processes(). Which
returns a list. It could easily be reformulted to be a generator.

----------------------------------------------------------------------

Unifying API and CLI:

- Instead of ls() -> Ls() -> setup(): parser could hold on to args,
  and then just invoke ls(args). Ls() could have parent class do arg
  parsing. Get rid of setup, doing post-parse work in Ls().

======================================================================

cat is "ls | expand". Add an abstraction mechanism? 

Yes, see pipelines as first-class objects:

cat = [f: ls f | expand]

======================================================================


Environment variables:

- current directory
- current thread (in case of a fork)
- Prompts (ps1, ps2)

----------------------------------------------------------------------

Doing more with pipelines:

Pipelines should be first-class objects:

- A form of abstraction: Assign a pipeline to a variable, then use it
  in commands and to build other pipelines.

- Pipelines can be passed to operators. E.g. there could be a join
  operator, taking two pipelines as inputs. In fact, the remote fork
  is such an operator.

File counts and sizes under current directory:

    file_counts_and_sizes = [ ls -fr | map (f: (1, f.size)) | red + + ]
    file_counts_and_sizes  # executes the pipeline

In a given directory:

    file_counts_and_sizes = [dir: ls -fr dir | map (f: (1, f.size)) | red + + ]

    file_counts_and_sizes '/tmp/foobar'

Composing:

    python_processes = [ ps | select (p: 'python' in p.commandline) ]
    python_processes | map (p: (p.pid, p.size, p.state))

Join, with args literal pipeline args:

    ext_sizes = [dir: ls -fr dir | map (f: (f.extension, f.size)) ]
    join [ ext_sizes '/home/jao' ] (L, R: L.extension == R.extension) [ ext_size '/home/alo' ]

capture op:

        capture PREDICATE destination

Apply predicate. If true, send to destination. Otherwise, send
downstream. Might want an option that sends everything downstream,
including things that are captured.

So this is basically if/then/else, (or if/then if the true items go
downstream also).

The destination could be a file or a pipeline.

Cascading these is a switch:

    if p1 [pipe1] | if p2 [pipe2] | if p3 [pipe3] | ...

----------------------------------------------------------------------

For objects to be rendered (file, process, error):

- __repr__ does the usual pythonic thing.

- render_compact: Without color, for use when the thing is rendered in a
  tuple of size > 1.

- render_full: With color, for use when the thing is rendered on its
  own, (tuple of size 1).

----------------------------------------------------------------------

- Allow cd to be mid-pipeline. It establishes an env that applies
  downstream only. I.e., logically, each op establishes a new COPY of
  the env, and can make changes not visible upstream.
